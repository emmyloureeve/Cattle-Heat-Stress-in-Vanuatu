{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63a27a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import netCDF4\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray\n",
    "import rasterio.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf537b5-7f9b-4dc5-aebf-58837ab85076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open dataset\n",
    "ds_1994_2023 = xr.open_dataset(r'1994_2023.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c4280e-3323-42e5-8872-e50d429fd584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset\n",
    "ds_1994_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb059d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alter 'time' from UTC to Vanuatu time (UTC + 11 hours)\n",
    "ds_1994_2023['time'] = ds_1994_2023['time'] + np.timedelta64(11, 'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c722da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the new variable BGT\n",
    "BGT = (1.33 * ds_1994_2023['temperature']) - (2.65 * np.sqrt(ds_1994_2023['temperature'])) + (3.21 * np.log10(ds_1994_2023['solar_radiation'] + 1)) + 3.5\n",
    "\n",
    "# Add BGT to the dataset\n",
    "ds_1994_2023['BGT'] = BGT\n",
    "\n",
    "# Re-assign names to the variables for the calculation\n",
    "RH = ds_1994_2023['relative_humidity']\n",
    "WS = ds_1994_2023['wind_speed']\n",
    "BGT = ds_1994_2023['BGT']\n",
    "\n",
    "# Calculate the different equations needed to calculate the HLI based on the BGT\n",
    "HLI_high = 8.62 + (0.38 * RH) + (1.55 * BGT) + np.exp(-WS + 2.4) - (0.5 * WS)\n",
    "HLI_low = 10.66 + (0.28 * RH) + (1.30 * BGT) - WS\n",
    "BGT_bl = 1 / (1 + (np.exp(-BGT - 25) / 2.25))\n",
    "HLI_bl = BGT_bl * HLI_high + (1 - BGT_bl) * HLI_low\n",
    "\n",
    "# Define a function to calculate the final HLI based on BGT conditions\n",
    "def calculate_final_HLI(BGT, HLI_high, HLI_low, HLI_bl):\n",
    "    return xr.where(BGT > 25, HLI_high, xr.where(BGT < 25, HLI_low, HLI_bl))\n",
    "\n",
    "# Calculate the final HLI\n",
    "final_HLI = calculate_final_HLI(BGT, HLI_high, HLI_low, HLI_bl)\n",
    "\n",
    "# Add the final HLI to the dataset\n",
    "ds_1994_2023['HLI'] = final_HLI\n",
    "\n",
    "# Take the HLI to calculate HL balance\n",
    "HLI = ds_1994_2023['HLI']\n",
    "\n",
    "# Define threshold HLI values\n",
    "threshold_high = 93\n",
    "threshold_low = 77\n",
    "\n",
    "# Calculate HL balance\n",
    "HL_balance = xr.where(HLI > threshold_high,\n",
    "                      HLI - threshold_high,\n",
    "                      xr.where(HLI < threshold_low,\n",
    "                               HLI - threshold_low,\n",
    "                               0))\n",
    "\n",
    "# Initialize AHL with zeros\n",
    "AHL = xr.zeros_like(HL_balance)\n",
    "\n",
    "# Perform cumulative sum with clipping to zero\n",
    "for i in range(1, len(AHL.time)):\n",
    "    # Calculate cumulative sum, ensuring no negative values\n",
    "    AHL[i] = xr.where(AHL[i-1] + HL_balance[i] < 0, 0, AHL[i-1] + HL_balance[i])\n",
    "\n",
    "# Add HL_balance and AHL to the dataset\n",
    "ds_1994_2023['HL_balance'] = HL_balance\n",
    "ds_1994_2023['AHL'] = AHL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9507c440-82aa-42f3-91b4-3bbd4d9c9e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset with HLI and AHL variables\n",
    "ds_1994_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f44b8c-f69b-4e9c-8445-d708ed18c940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the provinces shapefile\n",
    "provinces = gpd.read_file(r'vanuatu_provinces.shp')\n",
    "\n",
    "# Clean Provinces Data\n",
    "# Columns to delete\n",
    "columns_to_delete = ['ADM1_PCODE', 'ADM1_REF', 'ADM1ALT1EN', 'ADM1ALT2EN', 'ADM0_EN', 'ADM0_PCODE', 'date', 'validOn', 'validTo']\n",
    "\n",
    "# Delete the columns\n",
    "provinces = provinces.drop(columns=columns_to_delete)\n",
    "\n",
    "# Rename the column \n",
    "provinces = provinces.rename(columns={'ADM1_EN' : 'Province'})\n",
    "\n",
    "# Set CRS to EPSG:4326\n",
    "provinces = provinces.to_crs('EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd702dc-f916-40b7-b578-82af5224783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display provinces dataset\n",
    "provinces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4408887-cd9c-4667-8b2d-8e556a1f11f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask the dataset to include land cells only\n",
    "\n",
    "# Rasterise the shapefile\n",
    "shapes = [(geom, value) for geom, value in zip(provinces.geometry, provinces.index + 1)]\n",
    "out_shape = (len(ds_1994_2023.latitude), len(ds_1994_2023.longitude))\n",
    "transform = ds_1994_2023.rio.transform()\n",
    "\n",
    "province_raster = rasterio.features.rasterize(\n",
    "    shapes,\n",
    "    out_shape=out_shape,\n",
    "    transform=transform,\n",
    "    fill=0,\n",
    "    all_touched=True,\n",
    "    dtype='int32'\n",
    ")\n",
    "\n",
    "# Assign the rasterised province IDs to a new DataArray\n",
    "province_ids = xr.DataArray(\n",
    "    province_raster,\n",
    "    coords=[ds_1994_2023.latitude, ds_1994_2023.longitude],\n",
    "    dims=[\"latitude\", \"longitude\"]\n",
    ")\n",
    "\n",
    "# Add the province IDs to the dataset\n",
    "ds_1994_2023[\"province_id\"] = province_ids\n",
    "\n",
    "# Create a mapping from province IDs to province names\n",
    "province_mapping = {i + 1: name for i, name in enumerate(provinces['Province'])}\n",
    "\n",
    "# Create a new variable for province names\n",
    "ds_1994_2023['province_name'] = xr.DataArray(\n",
    "    np.vectorize(province_mapping.get)(ds_1994_2023['province_id'].data),\n",
    "    coords=ds_1994_2023['province_id'].coords,\n",
    "    dims=ds_1994_2023['province_id'].dims\n",
    ")\n",
    "\n",
    "# Display dataset\n",
    "ds_1994_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c05d10-71dd-4d11-8da5-618e255a0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the rasterized province IDs\n",
    "plt.figure(figsize=(10, 6))\n",
    "province_ids_plot = ds_1994_2023['province_id'].plot()\n",
    "plt.title('Rasterized Province IDs with Shapefile Overlay')\n",
    "\n",
    "# Overlay the shapefile\n",
    "provinces.boundary.plot(ax=province_ids_plot.axes, color='red', linewidth=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc76ffb-874b-4108-86a0-965e59472556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure consisitency throughout the dataset\n",
    "# Convert 'province_name' to a fixed-length string type\n",
    "ds_1994_2023['province_name'] = ds_1994_2023['province_name'].astype('str')\n",
    "\n",
    "# Convert province_id to float32\n",
    "ds_1994_2023['province_id'] = ds_1994_2023['province_id'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90108c56-d7c9-4938-86d4-253030045093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset (if possible, dataset maybe too large depending on the computing system)\n",
    "ds_1994_2023.to_netcdf(r'dataset.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e7489f-5138-4ca3-ba16-7dbc9d40eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take HLI and Province Name out of the xarray dataset and put it into a pandas dataset so that its easier to work with\n",
    "HLI_data = ds_1994_2023[['HLI', 'province_name']].to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c3a234-e4b2-46f5-accd-65c723ab968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'time' to datetime\n",
    "HLI_data['time'] = pd.to_datetime(HLI_data['time'])\n",
    "\n",
    "# Set 'time' as the index for resampling\n",
    "HLI_data.set_index('time', inplace=True)\n",
    "\n",
    "# Calculate daily maximum HLI for each grid cell\n",
    "daily_max_hli_df = HLI_data.groupby(['latitude', 'longitude', 'province_name'])['HLI'].resample('D').max().reset_index()\n",
    "\n",
    "# Display dataset\n",
    "daily_max_hli_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c777ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily maximum HLI for each grid cell\n",
    "daily_min_hli_df = HLI_data.groupby(['latitude', 'longitude', 'province_name'])['HLI'].resample('D').min().reset_index()\n",
    "\n",
    "# Display dataset\n",
    "daily_min_hli_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1973fe27-2835-4826-9c19-61e4b05bd7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert HLI_data and daily_max_hli_df to xarray dataset to save as a netcdf file\n",
    "Save_HLI_data = HLI_data.to_xarray()\n",
    "Save_HLI_data.to_netcdf(r'HLI_data.nc')\n",
    "\n",
    "D_Max_HLI = daily_max_hli_df.to_xarray()\n",
    "D_Max_HLI.to_netcdf(r'D_Max_HLI.nc')\n",
    "\n",
    "\n",
    "D_Min_HLI = daily_min_hli_df.to_xarray()\n",
    "D_Min_HLI.to_netcdf(r'D_Min_HLI.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a930fb-fff3-4c00-9c9c-2d3f7fe9c6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take AHL and Province Name out of the xarray dataset and put it into a pandas dataset so that its easier to work with\n",
    "AHL_data = ds_1994_2023[['AHL', 'province_name']].to_dataframe().reset_index()\n",
    "\n",
    "# Convert 'time' to datetime\n",
    "AHL_data['time'] = pd.to_datetime(AHL_data['time'])\n",
    "\n",
    "# Set 'time' as the index for resampling\n",
    "AHL_data.set_index('time', inplace=True)\n",
    "\n",
    "# Calculate daily maximum AHL for each grid cell across all years\n",
    "daily_max_ahl_df = AHL_data.groupby(['latitude', 'longitude', 'province_name'])['AHL'].resample('D').max().reset_index()\n",
    "\n",
    "daily_max_ahl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6374a7c7-33af-4e72-af0b-2bd3242a1aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert AHL_data and daily_max_ahl_df to xarray dataset to save as a netcdf file\n",
    "Save_AHL_data = AHL_data.to_xarray()\n",
    "Save_AHL_data.to_netcdf(r'AHL_data.nc')\n",
    "\n",
    "D_Max_AHL = daily_max_ahl_df.to_xarray()\n",
    "D_Max_AHL.to_netcdf(r'D_Max_AHL.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
